{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fb9442",
   "metadata": {},
   "source": [
    "# Floating Point Precision Comparison with JAX\n",
    "This notebook demonstrates how to compare different floating point precisions in JAX including bf16, fp16, fp32, and fp64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6998e4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX version: 0.7.1\n",
      "JAX backend: cpu\n",
      "Available devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "import psutil\n",
    "import tracemalloc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure JAX\n",
    "print(f\"JAX version: {jax.__version__}\")\n",
    "print(f\"JAX backend: {jax.default_backend()}\")\n",
    "print(f\"Available devices: {jax.devices()}\")\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c53750",
   "metadata": {},
   "source": [
    "Available precisions:\n",
    "- fp16: 16 bits (2 bytes) - Exponent: 5, Mantissa: 10\n",
    "- bf16: 16 bits (2 bytes) - Exponent: 8, Mantissa: 7\n",
    "- fp32: 32 bits (4 bytes) - Exponent: 8, Mantissa: 23\n",
    "- fp64: 64 bits (8 bytes) - Exponent: 11, Mantissa: 52"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e9f4d",
   "metadata": {},
   "source": [
    "### NOTE: CPU calculations are much slower than GPU calculations. Results may vary based on the hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d35295d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory and Performance Profiling Functions\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage in MB\"\"\"\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss / 1024 / 1024\n",
    "\n",
    "def measure_memory_and_time(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        # Start memory tracking\n",
    "        tracemalloc.start()\n",
    "        start_memory = get_memory_usage()\n",
    "        \n",
    "        # Time the function\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        jax.block_until_ready(result)  # Ensure computation is complete\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Get memory after execution\n",
    "        end_memory = get_memory_usage()\n",
    "        current, peak = tracemalloc.get_traced_memory()\n",
    "        tracemalloc.stop()\n",
    "        \n",
    "        return {\n",
    "            'result': result,\n",
    "            'execution_time': end_time - start_time,\n",
    "            'memory_delta': end_memory - start_memory,\n",
    "            'peak_memory': peak / 1024 / 1024,  # Convert to MB\n",
    "            'current_memory': current / 1024 / 1024  # Convert to MB\n",
    "        }\n",
    "    return wrapper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a15b461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Functions for Different Operations\n",
    "@measure_memory_and_time\n",
    "def matrix_multiplication_test(dtype, shape):\n",
    "    \"\"\"Test matrix multiplication with given precision\"\"\"\n",
    "    key = jax.random.PRNGKey(42)\n",
    "    key1, key2 = jax.random.split(key)\n",
    "    \n",
    "    def matmul_operation():\n",
    "        a = jax.random.normal(key1, shape, dtype=dtype)\n",
    "        b = jax.random.normal(key2, shape, dtype=dtype)\n",
    "        return jnp.dot(a, b)\n",
    "    \n",
    "    return matmul_operation()\n",
    "\n",
    "    \n",
    "@measure_memory_and_time\n",
    "def neural_network_forward_pass_test(dtype, input_size, hidden_size, output_size):\n",
    "    \"\"\"Test a simple neural network forward pass\"\"\"\n",
    "    key = jax.random.PRNGKey(123)\n",
    "    keys = jax.random.split(key, 3)\n",
    "    \n",
    "    def nn_forward():\n",
    "        # Initialize weights\n",
    "        W1 = jax.random.normal(keys[0], (input_size, hidden_size), dtype=dtype)\n",
    "        b1 = jax.random.normal(keys[1], (hidden_size,), dtype=dtype)\n",
    "        W2 = jax.random.normal(keys[2], (hidden_size, output_size), dtype=dtype)\n",
    "        b2 = jax.random.normal(keys[2], (output_size,), dtype=dtype)\n",
    "        \n",
    "        # Input data\n",
    "        x = jax.random.normal(keys[0], (input_size,), dtype=dtype)\n",
    "        \n",
    "        # Forward pass\n",
    "        h = jnp.tanh(jnp.dot(x, W1) + b1)\n",
    "        y = jnp.dot(h, W2) + b2\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    return nn_forward()\n",
    "\n",
    "@measure_memory_and_time\n",
    "def precision_test(dtype, test_values):\n",
    "    \"\"\"Test numerical precision with specific values\"\"\"\n",
    "    def precision_operation():\n",
    "        # Convert test values to the specified dtype\n",
    "        values = jnp.array(test_values, dtype=dtype)\n",
    "        \n",
    "        # Perform some operations that might reveal precision differences\n",
    "        result1 = jnp.sum(values)\n",
    "        result2 = jnp.mean(values)\n",
    "        result3 = jnp.std(values)\n",
    "        result4 = jnp.prod(values)\n",
    "        \n",
    "        return jnp.array([result1, result2, result3, result4])\n",
    "    \n",
    "    return precision_operation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f370dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Comparison Function\n",
    "PRECISIONS = {\n",
    "    'fp16': jnp.float16,\n",
    "    'bf16': jnp.bfloat16, \n",
    "    'fp32': jnp.float32,\n",
    "    'fp64': jnp.float64\n",
    "}\n",
    "\n",
    "def compare_precisions(operation_name, test_func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Compare all precisions for a given operation and return a summary table (pandas DataFrame).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    results = []\n",
    "   \n",
    "    for precision_name, dtype in PRECISIONS.items():\n",
    "        # Run the test\n",
    "        result = test_func(dtype, *args, **kwargs)\n",
    "        row = {\n",
    "            'Operation': operation_name,\n",
    "            'Precision': precision_name,\n",
    "            'Execution Time (s)': result.get('execution_time', None),\n",
    "            'Memory Delta (MB)': result.get('memory_delta', None),\n",
    "            'Peak Memory (MB)': result.get('peak_memory', None),\n",
    "            'Result Shape': getattr(result.get('result', None), 'shape', None),\n",
    "            'Result Dtype': str(getattr(result.get('result', None), 'dtype', None))\n",
    "        }\n",
    "    \n",
    "        \n",
    "        results.append(row)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2eac1931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "      <th>Memory Delta (MB)</th>\n",
       "      <th>Peak Memory (MB)</th>\n",
       "      <th>Result Shape</th>\n",
       "      <th>Result Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Matrix Multiplication (1000x1000)</td>\n",
       "      <td>fp16</td>\n",
       "      <td>1.024406</td>\n",
       "      <td>448.609375</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>(5000, 5000)</td>\n",
       "      <td>float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Matrix Multiplication (1000x1000)</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0.977660</td>\n",
       "      <td>49.328125</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>(5000, 5000)</td>\n",
       "      <td>bfloat16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matrix Multiplication (1000x1000)</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.942557</td>\n",
       "      <td>-49.250000</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>(5000, 5000)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matrix Multiplication (1000x1000)</td>\n",
       "      <td>fp64</td>\n",
       "      <td>0.927667</td>\n",
       "      <td>7.843750</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>(5000, 5000)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Operation Precision  Execution Time (s)  \\\n",
       "0  Matrix Multiplication (1000x1000)      fp16            1.024406   \n",
       "1  Matrix Multiplication (1000x1000)      bf16            0.977660   \n",
       "2  Matrix Multiplication (1000x1000)      fp32            0.942557   \n",
       "3  Matrix Multiplication (1000x1000)      fp64            0.927667   \n",
       "\n",
       "   Memory Delta (MB)  Peak Memory (MB)  Result Shape Result Dtype  \n",
       "0         448.609375          0.013244  (5000, 5000)      float16  \n",
       "1          49.328125          0.008247  (5000, 5000)     bfloat16  \n",
       "2         -49.250000          0.008247  (5000, 5000)      float32  \n",
       "3           7.843750          0.008503  (5000, 5000)      float32  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "matrix_shape = (5000, 5000)\n",
    "results_matrix_multiplication = compare_precisions(\n",
    "    \"Matrix Multiplication (1000x1000)\", \n",
    "    matrix_multiplication_test, \n",
    "    matrix_shape\n",
    ")\n",
    "\n",
    "results_matrix_multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bf65405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "      <th>Memory Delta (MB)</th>\n",
       "      <th>Peak Memory (MB)</th>\n",
       "      <th>Result Shape</th>\n",
       "      <th>Result Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Forward Pass (784-&gt;256-&gt;10)</td>\n",
       "      <td>fp16</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>11.593750</td>\n",
       "      <td>0.020218</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neural Network Forward Pass (784-&gt;256-&gt;10)</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>4.812500</td>\n",
       "      <td>0.015495</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>bfloat16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neural Network Forward Pass (784-&gt;256-&gt;10)</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>7.156250</td>\n",
       "      <td>0.015388</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Neural Network Forward Pass (784-&gt;256-&gt;10)</td>\n",
       "      <td>fp64</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>(10,)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Operation Precision  Execution Time (s)  \\\n",
       "0  Neural Network Forward Pass (784->256->10)      fp16            0.006846   \n",
       "1  Neural Network Forward Pass (784->256->10)      bf16            0.004057   \n",
       "2  Neural Network Forward Pass (784->256->10)      fp32            0.003193   \n",
       "3  Neural Network Forward Pass (784->256->10)      fp64            0.002193   \n",
       "\n",
       "   Memory Delta (MB)  Peak Memory (MB) Result Shape Result Dtype  \n",
       "0          11.593750          0.020218        (10,)      float16  \n",
       "1           4.812500          0.015495        (10,)     bfloat16  \n",
       "2           7.156250          0.015388        (10,)      float32  \n",
       "3           0.140625          0.015644        (10,)      float32  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_neural_network = compare_precisions(\n",
    "    \"Neural Network Forward Pass (784->256->10)\", \n",
    "    neural_network_forward_pass_test, \n",
    "    784, 256, 10\n",
    ")\n",
    "\n",
    "results_neural_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91876422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Operation</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Execution Time (s)</th>\n",
       "      <th>Memory Delta (MB)</th>\n",
       "      <th>Peak Memory (MB)</th>\n",
       "      <th>Result Shape</th>\n",
       "      <th>Result Dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Numerical Precision Test</td>\n",
       "      <td>fp16</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>2.890625</td>\n",
       "      <td>0.022018</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Numerical Precision Test</td>\n",
       "      <td>bf16</td>\n",
       "      <td>0.010344</td>\n",
       "      <td>2.109375</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>bfloat16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Numerical Precision Test</td>\n",
       "      <td>fp32</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>1.734375</td>\n",
       "      <td>0.017090</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Numerical Precision Test</td>\n",
       "      <td>fp64</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>float32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Operation Precision  Execution Time (s)  Memory Delta (MB)  \\\n",
       "0  Numerical Precision Test      fp16            0.004691           2.890625   \n",
       "1  Numerical Precision Test      bf16            0.010344           2.109375   \n",
       "2  Numerical Precision Test      fp32            0.021163           1.734375   \n",
       "3  Numerical Precision Test      fp64            0.000902           0.031250   \n",
       "\n",
       "   Peak Memory (MB) Result Shape Result Dtype  \n",
       "0          0.022018         (4,)      float16  \n",
       "1          0.016884         (4,)     bfloat16  \n",
       "2          0.017090         (4,)      float32  \n",
       "3          0.017176         (4,)      float32  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Test with values that might reveal precision differences\n",
    "test_values = [0.1, 0.2, 0.3, 0.4, 0.5, 1e-6, 1e6, np.pi, np.e]\n",
    "\n",
    "results_precision_test = compare_precisions(\n",
    "    \"Numerical Precision Test\", \n",
    "    precision_test, \n",
    "    test_values\n",
    ")\n",
    "\n",
    "\n",
    "results_precision_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a5fe9f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'result': Array([ 0.7227,  4.688 , -0.503 ,  3.291 , -6.97  ], dtype=float16), 'execution_time': 0.03721189498901367, 'memory_delta': 18.4375, 'peak_memory': 0.041400909423828125, 'current_memory': 0.03329658508300781}\n",
      "Input dtype: bfloat16\n",
      "Weight dtype: float32\n",
      "Output dtype: float16\n",
      "Output shape: (5,)\n",
      "Memory usage:\n",
      "  Input: 20 bytes\n",
      "  Weights: 220 bytes\n",
      "  Output: 10 bytes\n",
      "  Total: 250 bytes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of mixed precision training\n",
    "\n",
    "# Create a simple model\n",
    "key = jax.random.PRNGKey(42)\n",
    "key1, key2, key3 = jax.random.split(key, 3)\n",
    "\n",
    "# Model parameters in FP32 (for stability)\n",
    "W = jax.random.normal(key1, (10, 5), dtype=jnp.float32)\n",
    "b = jax.random.normal(key2, (5,), dtype=jnp.float32)\n",
    "\n",
    "# Input data in bf16 (for memory efficiency)\n",
    "x = jax.random.normal(key3, (10,), dtype=jnp.bfloat16)\n",
    "\n",
    "@measure_memory_and_time\n",
    "def forward_pass(x, W, b):\n",
    "    # Convert to FP64 for computation\n",
    "    x_fp32 = x.astype(jnp.float64)\n",
    "    W_fp32 = W.astype(jnp.float64)\n",
    "    b_fp32 = b.astype(jnp.float64)\n",
    "    \n",
    "    # Forward pass\n",
    "    y = jnp.dot(x_fp32, W_fp32) + b_fp32\n",
    "    \n",
    "    # Convert back to FP16 for memory efficiency\n",
    "    return y.astype(jnp.float16)\n",
    "\n",
    "# Run forward pass\n",
    "result = forward_pass(x, W, b)\n",
    "print(result)\n",
    "\n",
    "print(f\"Input dtype: {x.dtype}\")\n",
    "print(f\"Weight dtype: {W.dtype}\")\n",
    "print(f\"Output dtype: {result['result'].dtype}\") \n",
    "print(f\"Output shape: {result['result'].shape}\")\n",
    "print(f\"Memory usage:\")\n",
    "print(f\"  Input: {x.nbytes} bytes\")\n",
    "print(f\"  Weights: {W.nbytes + b.nbytes} bytes\")\n",
    "print(f\"  Output: {result['result'].nbytes} bytes\")\n",
    "print(f\"  Total: {x.nbytes + W.nbytes + b.nbytes + result['result'].nbytes} bytes\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
